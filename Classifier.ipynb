{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "    global torch, np, resnext, Compose, Scale, CenterCrop, ToTensor, Normalize, TemporalCenterCrop, spatial_transforms, \\\n",
    "        target_transforms, temporal_transforms, PILIm, ImageOps, ImShow, plt, cv2, os, glob, csv, \\\n",
    "        size, norm_value, duration, classes\n",
    "    \n",
    "    import torch\n",
    "    import numpy as np\n",
    "    import resnext\n",
    "    from spatial_transforms import Compose, Scale, CenterCrop, ToTensor, Normalize\n",
    "    from temporal_transforms import TemporalCenterCrop\n",
    "    import spatial_transforms\n",
    "    import target_transforms\n",
    "    import temporal_transforms\n",
    "    from PIL import Image as PILIm\n",
    "    from PIL import ImageOps\n",
    "    from IPython.display import Image as ImShow\n",
    "    import matplotlib.pyplot as plt\n",
    "    #import torchvision\n",
    "    import cv2\n",
    "    import os\n",
    "    import glob\n",
    "    import csv\n",
    "\n",
    "    size = 112\n",
    "    norm_value = 1\n",
    "    duration = 32\n",
    "    classes = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD MODEL\n",
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath, map_location='cpu')\n",
    "\n",
    "    my_dict = checkpoint['state_dict']\n",
    "    my_dict_copy = my_dict.copy()\n",
    "\n",
    "    for key in my_dict_copy.keys():\n",
    "        newkey = key[7:]\n",
    "        my_dict[newkey] = my_dict.pop(key)\n",
    "\n",
    "    checkpoint['state_dict'] = my_dict \n",
    "    \n",
    "    \n",
    "    \n",
    "    model = resnext.resnet101(\n",
    "        num_classes=classes,\n",
    "        shortcut_type='B',\n",
    "        cardinality=32,\n",
    "        sample_size=size,\n",
    "        sample_duration=duration)\n",
    "\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean(normval=255):\n",
    "    return [114.7748 / normval, 107.7354 / normval, 99.4750 / normval ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE THE TRANSFORMS\n",
    "def getTransforms():\n",
    "    scales = [1]\n",
    "    for i in range(1, 5):\n",
    "        scales.append(scales[-1] * 0.84089641525)\n",
    "        \n",
    "    norm_method = Normalize(get_mean(norm_value), [1, 1, 1])\n",
    "            \n",
    "    spatial_transform = spatial_transforms.Compose([\n",
    "        Scale(size),\n",
    "        CenterCrop(size),\n",
    "        ToTensor(norm_value), norm_method \n",
    "    ])\n",
    "\n",
    "    temporal_transform = spatial_transforms.Compose([\n",
    "        TemporalCenterCrop(duration) \n",
    "    ])\n",
    "    return spatial_transform, temporal_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClearDir(dirname, filetype='jpg'):\n",
    "    import glob, os, os.path\n",
    "\n",
    "    filelist = glob.glob(os.path.join(dirname, \"*.\"+filetype))\n",
    "    for f in filelist:\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlayVidInput():\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import random\n",
    "    from os.path import isfile, join\n",
    "    pathIn= 'vidinput/'\n",
    "    #print(pathIn)\n",
    "    pathOut = './gesturevideos/video' + str(random.randint(0,1000)) + '.avi'\n",
    "    fps = 15\n",
    "    frame_array = []\n",
    "    files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
    "    #for sorting the file names properly\n",
    "    files.sort(key = lambda x: x[5:-4])\n",
    "    files.sort()\n",
    "    frame_array = []\n",
    "    files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
    "    #for sorting the file names properly\n",
    "    files.sort(key = lambda x: x[5:-4])\n",
    "    for i in range(len(files)):\n",
    "        filename=pathIn + files[i]\n",
    "        #reading each files\n",
    "        img = cv2.imread(filename)\n",
    "        height, width, layers = img.shape\n",
    "        size = (width,height)\n",
    "    \n",
    "        #inserting the frames into an image array\n",
    "        frame_array.append(img)\n",
    "    out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
    "    for i in range(len(frame_array)):\n",
    "        # writing to a image array\n",
    "        out.write(frame_array[i])\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TURN THE 37 FRAMES FROM ./TESTVID INTO TENSOR INPUT <1,3,32,112,112>\n",
    "def TransformData(spatial_transform, temporal_transform, framesTT, Show=False):\n",
    "    a=[]\n",
    "    for frame in framesTT:\n",
    "        image = PILIm.fromarray(frame.astype('uint8'), mode='RGB').convert(\"RGB\")\n",
    "        image.save(\"YOLO.png\")\n",
    "        a.append(image)\n",
    "\n",
    "    input_temp = temporal_transform(a)\n",
    "    \n",
    "    if Show:\n",
    "        ClearDir('vidinput/','png')\n",
    "        count = 0\n",
    "        for image in input_temp:\n",
    "            image = np.array(image)\n",
    "            if count<10:\n",
    "                #image.save(\"vidinput/frame0%d.png\" % count)\n",
    "                cv2.imwrite(\"vidinput/frame0%d.png\" % count, image)\n",
    "\n",
    "            else:\n",
    "                cv2.imwrite(\"vidinput/frame%d.png\" % count, image)\n",
    "            count +=1\n",
    "        PlayVidInput()\n",
    "    \n",
    "    #for image in input_temp:\n",
    "    #    image.save(\"noncroppedimage.png\")\n",
    "    \n",
    "    spatial_transform.randomize_parameters()\n",
    "    input_spat = [spatial_transform(image) for image in input_temp]\n",
    "    \n",
    "    #for image in input_spat:\n",
    "    #    print(type(image))\n",
    "    #    image_np = image.numpy()\n",
    "    #    im = PILIm.fromarray(image_np.astype('uint8'), 'RGB')\n",
    "    #    im.save(\"croppedimage.png\")\n",
    "    \n",
    "    im_dim = input_spat[0].size()[-2:]\n",
    "    clip = torch.cat(input_spat, 0).view((duration, -1) + im_dim).permute(1, 0, 2, 3)\n",
    "    input = clip[None, :, :, :, :] #Add 5th Dimension; batchSize=1\n",
    "    #print(input.shape)\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET PREDICTIONS\n",
    "def ClassifyOutput(out, classestxt):\n",
    "    with open(classestxt) as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "    #_, index = torch.max(out, 1)\n",
    "    percentage = torch.nn.functional.softmax(out, dim=1)[0]\n",
    "    #print(classes[index[0]], percentage[index[0]].item())\n",
    "    \n",
    "    _, indices = torch.sort(out, descending=True)\n",
    "    #print([(classes[idx], percentage[idx].item()) for idx in indices[0][:80]])\n",
    "    \n",
    "    return(classes, indices, percentage)\n",
    "    \n",
    "    #return(classes[indices[0][0]], classes[indices[0][1]])\n",
    "    \n",
    "    #return(classes[index[0]], classes[index[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classify(framesTT, verbose=False):\n",
    "    load()\n",
    "    model = load_checkpoint('jester_resnext_101_RGB_32.pth')\n",
    "    \n",
    "    spatialt, temporalt = getTransforms()\n",
    "    input = TransformData(spatialt, temporalt, framesTT, verbose).cuda()\n",
    "    model.eval()\n",
    "    model = model.cuda()\n",
    "    out = model(input)\n",
    "\n",
    "    return ClassifyOutput(out, 'jesterclasses.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
